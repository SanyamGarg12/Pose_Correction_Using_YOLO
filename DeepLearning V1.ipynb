{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a4b739",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206691b",
   "metadata": {},
   "source": [
    "# 2. Check the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b22970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv('./labeling/benchpress_coords.csv')\n",
    "df_dead = pd.read_csv('./labeling/deadlift_coords.csv')\n",
    "df_squat = pd.read_csv('./labeling/squat_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098732e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca142bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe058cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03291a0",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing & Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4debbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bench_data = np.loadtxt(\"./labeling/benchpress_coords.csv\", delimiter=\",\", dtype=str, skiprows=1)\n",
    "labels = bench_data[:, 0]\n",
    "bench_data = bench_data[:, 1:]  # Select all columns except the first column\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "\n",
    "# Handle missing values\n",
    "bench_data = np.nan_to_num(bench_data)\n",
    "\n",
    "bench_data = bench_data.astype(float)\n",
    "\n",
    "# Split data\n",
    "bench_X_train, bench_X_test, bench_y_train, bench_y_test = train_test_split(bench_data, labels, test_size=0.25)\n",
    "\n",
    "# Convert to tensor\n",
    "bench_X_train = torch.tensor(bench_X_train)\n",
    "bench_X_test = torch.tensor(bench_X_test)\n",
    "bench_y_train = torch.tensor(bench_y_train)\n",
    "bench_y_test = torch.tensor(bench_y_test)\n",
    "\n",
    "# Convert to float\n",
    "bench_X_train = bench_X_train.float()\n",
    "bench_X_test = bench_X_test.float()\n",
    "bench_y_train = bench_y_train.float()\n",
    "bench_y_test = bench_y_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36cffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "squat_data = np.loadtxt(\"./labeling/squat_coords.csv\", delimiter=\",\", dtype=str, skiprows=1)\n",
    "labels_squat = squat_data[:, 0]\n",
    "squat_data = squat_data[:, 1:]  # Select all columns except the first column\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels_squat = encoder.fit_transform(labels_squat.reshape(-1, 1))\n",
    "\n",
    "# Handle missing values\n",
    "squat_data = np.nan_to_num(squat_data)\n",
    "\n",
    "squat_data = squat_data.astype(float)\n",
    "\n",
    "# Split data\n",
    "squat_X_train, squat_X_test, squat_y_train, squat_y_test = train_test_split(squat_data, labels_squat, test_size=0.25)\n",
    "\n",
    "# Convert to tensor\n",
    "squat_X_train = torch.tensor(squat_X_train)\n",
    "squat_X_test = torch.tensor(squat_X_test)\n",
    "squat_y_train = torch.tensor(squat_y_train)\n",
    "squat_y_test = torch.tensor(squat_y_test)\n",
    "\n",
    "# Convert to float\n",
    "squat_X_train = squat_X_train.float()\n",
    "squat_X_test = squat_X_test.float()\n",
    "squat_y_train = squat_y_train.float()\n",
    "squat_y_test = squat_y_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "deadlift_data = np.loadtxt(\"./labeling/deadlift_coords.csv\", delimiter=\",\", dtype=str, skiprows=1)\n",
    "labels_deadlift = deadlift_data[:, 0]\n",
    "deadlift_data = deadlift_data[:, 1:]  # Select all columns except the first column\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels_deadlift = encoder.fit_transform(labels_deadlift.reshape(-1, 1))\n",
    "\n",
    "# Handle missing values\n",
    "deadlift_data = np.nan_to_num(deadlift_data)\n",
    "\n",
    "deadlift_data = deadlift_data.astype(float)\n",
    "\n",
    "# Split data\n",
    "deadlift_X_train, deadlift_X_test, deadlift_y_train, deadlift_y_test = train_test_split(deadlift_data, labels_deadlift, test_size=0.25)\n",
    "\n",
    "# Convert to tensor\n",
    "deadlift_X_train = torch.tensor(deadlift_X_train)\n",
    "deadlift_X_test = torch.tensor(deadlift_X_test)\n",
    "deadlift_y_train = torch.tensor(deadlift_y_train)\n",
    "deadlift_y_test = torch.tensor(deadlift_y_test)\n",
    "\n",
    "# Convert to float\n",
    "deadlift_X_train = deadlift_X_train.float()\n",
    "deadlift_X_test = deadlift_X_test.float()\n",
    "deadlift_y_train = deadlift_y_train.float()\n",
    "deadlift_y_test = deadlift_y_test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122dfa3",
   "metadata": {},
   "source": [
    "# 4. Construct Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c55c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c59927",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56f3fb",
   "metadata": {},
   "source": [
    "### Bench Press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85728780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DeepClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(self.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_size = 132\n",
    "output_size = 6\n",
    "bench_model = DeepClassifier(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdac53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_criterion = nn.BCELoss()\n",
    "bench_optimizer = optim.Adam(bench_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_train_losses = []\n",
    "bench_test_losses = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    bench_model.train()\n",
    "    bench_optimizer.zero_grad()\n",
    "    bench_outputs = bench_model(bench_X_train)\n",
    "    bench_loss = bench_criterion(bench_outputs, bench_y_train)\n",
    "    bench_loss.backward()\n",
    "    bench_optimizer.step()\n",
    "    bench_train_losses.append(bench_loss.item())\n",
    "    \n",
    "    bench_model.eval()\n",
    "    with torch.no_grad():\n",
    "        bench_test_outputs = bench_model(bench_X_test)\n",
    "        bench_test_loss = bench_criterion(bench_test_outputs, bench_y_test)\n",
    "        bench_test_losses.append(bench_test_loss.item())\n",
    "\n",
    "plt.plot(range(1, epochs+1), bench_train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), bench_test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = bench_model(bench_X_test)\n",
    "    test_loss = bench_criterion(test_outputs, bench_y_test)\n",
    "    print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples from test dataset\n",
    "num_samples_to_test = 5  # Number of samples to check\n",
    "for i in range(num_samples_to_test):\n",
    "    sample_index = i\n",
    "    input_sample = bench_X_test[sample_index]  # Input data\n",
    "    target_sample = bench_y_test[sample_index]  # Actual target (ground truth) data\n",
    "\n",
    "    # Convert input data to tensor\n",
    "    input_tensor = torch.tensor(input_sample, dtype=torch.float32)\n",
    "\n",
    "    # Input to model to generate prediction\n",
    "    bench_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = bench_model(input_tensor.unsqueeze(0))  # Add batch dimension using unsqueeze\n",
    "\n",
    "    # Print prediction results\n",
    "    print(f\"Sample {sample_index + 1}:\")\n",
    "    print(\"Input data:\", input_sample)\n",
    "    print(\"Actual target data:\", target_sample)\n",
    "    print(\"Predicted data:\", torch.argmax(prediction))  # Output predicted class (not probability)\n",
    "    probabilities = prediction.squeeze().tolist()  # Convert tensor to list\n",
    "    probabilities_str = [f\"{prob:.4f}\" for prob in probabilities]\n",
    "    print(\"Prediction probabilities:\", probabilities_str)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cacd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_probs = bench_model(bench_X_test)\n",
    "\n",
    "threshold = 0.8  # Set threshold\n",
    "predicted_labels = (predicted_probs > threshold).numpy().astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(bench_y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(bench_y_test, predicted_labels, average='micro')\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(bench_y_test, predicted_labels, average='micro')\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(bench_y_test, predicted_labels, average='micro')\n",
    "print(f\"F1 score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = multilabel_confusion_matrix(bench_y_test, predicted_labels)\n",
    "\n",
    "def plot_multilabel_confusion_matrix(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    fig, axes = plt.subplots(nrows=num_classes, ncols=1, figsize=(8, 6 * num_classes))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        sns.heatmap(confusion_matrix[i], annot=True, cmap=\"Blues\", fmt=\"d\", ax=axes[i])\n",
    "        axes[i].set_title(f\"Class {i+1} Confusion Matrix\")\n",
    "        axes[i].set_xlabel(\"Predicted label\")\n",
    "        axes[i].set_ylabel(\"True label\")\n",
    "        axes[i].set_xticklabels(['True', 'False'])\n",
    "        axes[i].set_yticklabels(['True', 'False'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize multilabel confusion matrix\n",
    "plot_multilabel_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fffb7",
   "metadata": {},
   "source": [
    "### Squat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_size = 132\n",
    "output_size = 8\n",
    "squat_model = DeepClassifier(input_size, output_size)\n",
    "squat_criterion = nn.BCELoss()\n",
    "squat_optimizer = optim.Adam(squat_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "squat_train_losses = []\n",
    "squat_test_losses = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    squat_model.train()\n",
    "    squat_optimizer.zero_grad()\n",
    "    squat_outputs = squat_model(squat_X_train)\n",
    "    squat_loss = squat_criterion(squat_outputs, squat_y_train)\n",
    "    squat_loss.backward()\n",
    "    squat_optimizer.step()\n",
    "    squat_train_losses.append(squat_loss.item())\n",
    "    \n",
    "    squat_model.eval()\n",
    "    with torch.no_grad():\n",
    "        squat_test_outputs = squat_model(squat_X_test)\n",
    "        squat_test_loss = squat_criterion(squat_test_outputs, squat_y_test)\n",
    "        squat_test_losses.append(squat_test_loss.item())\n",
    "\n",
    "plt.plot(range(1, epochs+1), squat_train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), squat_test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "squat_model.eval()\n",
    "with torch.no_grad():\n",
    "    squat_test_outputs = squat_model(squat_X_test)\n",
    "    squat_test_loss = squat_criterion(squat_test_outputs, squat_y_test)\n",
    "    print(f'Test Loss: {squat_test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples from test dataset\n",
    "num_samples_to_test = 5  # Number of samples to check\n",
    "for i in range(num_samples_to_test):\n",
    "    sample_index = i\n",
    "    input_sample = squat_X_test[sample_index]  # Input data\n",
    "    target_sample = squat_y_test[sample_index]  # Actual target (ground truth) data\n",
    "\n",
    "    # Convert input data to tensor\n",
    "    input_tensor = torch.tensor(input_sample, dtype=torch.float32)\n",
    "\n",
    "    # Input to model to generate prediction\n",
    "    squat_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = squat_model(input_tensor.unsqueeze(0))  # Add batch dimension using unsqueeze\n",
    "\n",
    "    # Print prediction results\n",
    "    print(f\"Sample {sample_index + 1}:\")\n",
    "    print(\"Input data:\", input_sample)\n",
    "    print(\"Actual target data:\", target_sample)\n",
    "    print(\"Predicted data:\", torch.argmax(prediction))  # Output predicted class (not probability)\n",
    "    probabilities = prediction.squeeze().tolist()  # Convert tensor to list\n",
    "    probabilities_str = [f\"{prob:.4f}\" for prob in probabilities]\n",
    "    print(\"Prediction probabilities:\", probabilities_str)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "squat_model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_probs = squat_model(squat_X_test)\n",
    "\n",
    "threshold = 0.8  # Set threshold\n",
    "predicted_labels = (predicted_probs > threshold).numpy().astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(squat_y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(squat_y_test, predicted_labels, average='micro')\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(squat_y_test, predicted_labels, average='micro')\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(squat_y_test, predicted_labels, average='micro')\n",
    "print(f\"F1 score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = multilabel_confusion_matrix(squat_y_test, predicted_labels)\n",
    "\n",
    "def plot_multilabel_confusion_matrix(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    fig, axes = plt.subplots(nrows=num_classes, ncols=1, figsize=(8, 6 * num_classes))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        sns.heatmap(confusion_matrix[i], annot=True, cmap=\"Blues\", fmt=\"d\", ax=axes[i])\n",
    "        axes[i].set_title(f\"Class {i+1} Confusion Matrix\")\n",
    "        axes[i].set_xlabel(\"Predicted label\")\n",
    "        axes[i].set_ylabel(\"True label\")\n",
    "        axes[i].set_xticklabels(['True', 'False'])\n",
    "        axes[i].set_yticklabels(['True', 'False'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize multilabel confusion matrix\n",
    "plot_multilabel_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50889ab8",
   "metadata": {},
   "source": [
    "### Deadlift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_size = 132\n",
    "output_size = 8\n",
    "deadlift_model = DeepClassifier(input_size, output_size)\n",
    "deadlift_criterion = nn.BCELoss()\n",
    "deadlift_optimizer = optim.Adam(deadlift_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlift_train_losses = []\n",
    "deadlift_test_losses = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    deadlift_model.train()\n",
    "    deadlift_optimizer.zero_grad()\n",
    "    deadlift_outputs = deadlift_model(deadlift_X_train)\n",
    "    deadlift_loss = deadlift_criterion(deadlift_outputs, deadlift_y_train)\n",
    "    deadlift_loss.backward()\n",
    "    deadlift_optimizer.step()\n",
    "    deadlift_train_losses.append(deadlift_loss.item())\n",
    "    \n",
    "    deadlift_model.eval()\n",
    "    with torch.no_grad():\n",
    "        deadlift_test_outputs = deadlift_model(deadlift_X_test)\n",
    "        deadlift_test_loss = deadlift_criterion(deadlift_test_outputs, deadlift_y_test)\n",
    "        deadlift_test_losses.append(deadlift_test_loss.item())\n",
    "\n",
    "plt.plot(range(1, epochs+1), deadlift_train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), deadlift_test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlift_model.eval()\n",
    "with torch.no_grad():\n",
    "    deadlift_test_outputs = deadlift_model(deadlift_X_test)\n",
    "    deadlift_test_loss = deadlift_criterion(deadlift_test_outputs, deadlift_y_test)\n",
    "    print(f'Test Loss: {deadlift_test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262be563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples from test dataset\n",
    "num_samples_to_test = 5  # Number of samples to check\n",
    "for i in range(num_samples_to_test):\n",
    "    sample_index = i\n",
    "    input_sample = deadlift_X_test[sample_index]  # Input data\n",
    "    target_sample = deadlift_y_test[sample_index]  # Actual target (ground truth) data\n",
    "\n",
    "    # Convert input data to tensor\n",
    "    input_tensor = torch.tensor(input_sample, dtype=torch.float32)\n",
    "\n",
    "    # Input to model to generate prediction\n",
    "    deadlift_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = deadlift_model(input_tensor.unsqueeze(0))  # Add batch dimension using unsqueeze\n",
    "\n",
    "    # Print prediction results\n",
    "    print(f\"Sample {sample_index + 1}:\")\n",
    "    print(\"Input data:\", input_sample)\n",
    "    print(\"Actual target data:\", target_sample)\n",
    "    print(\"Predicted data:\", torch.argmax(prediction))  # Output predicted class (not probability)\n",
    "    probabilities = prediction.squeeze().tolist()  # Convert tensor to list\n",
    "    probabilities_str = [f\"{prob:.4f}\" for prob in probabilities]\n",
    "    print(\"Prediction probabilities:\", probabilities_str)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11299320",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlift_model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_probs = deadlift_model(deadlift_X_test)\n",
    "\n",
    "threshold = 0.8  # Set threshold\n",
    "predicted_labels = (predicted_probs > threshold).numpy().astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(deadlift_y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(deadlift_y_test, predicted_labels, average='micro')\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(deadlift_y_test, predicted_labels, average='micro')\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(deadlift_y_test, predicted_labels, average='micro')\n",
    "print(f\"F1 score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = multilabel_confusion_matrix(deadlift_y_test, predicted_labels)\n",
    "\n",
    "def plot_multilabel_confusion_matrix(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    fig, axes = plt.subplots(nrows=num_classes, ncols=1, figsize=(8, 6 * num_classes))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        sns.heatmap(confusion_matrix[i], annot=True, cmap=\"Blues\", fmt=\"d\", ax=axes[i])\n",
    "        axes[i].set_title(f\"Class {i+1} Confusion Matrix\")\n",
    "        axes[i].set_xlabel(\"Predicted label\")\n",
    "        axes[i].set_ylabel(\"True label\")\n",
    "        axes[i].set_xticklabels(['True', 'False'])\n",
    "        axes[i].set_yticklabels(['True', 'False'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize multilabel confusion matrix\n",
    "plot_multilabel_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb5693",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c44f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Bench Press\n",
    "with open('benchpress_model_deep.pkl', 'wb') as f:\n",
    "    pickle.dump(bench_model, f)\n",
    "\n",
    "# Squat\n",
    "with open('squat_model_deep.pkl', 'wb') as f:\n",
    "    pickle.dump(squat_model, f)\n",
    "\n",
    "# Deadlift\n",
    "with open('deadlift_model_deep.pkl', 'wb') as f:\n",
    "    pickle.dump(deadlift_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeba6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "squat_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlift_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc644d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
